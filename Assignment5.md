# ASSIGNMENT #5 (COMPLETE)

## Objective
This week you will:  
Work with branches while collaborating with others in the class. 

## PREREQUISITES  

### TEAMS
- You will work with with the following teams


| Team      | Members |
| -------- | ----------- |
| Team A   |  Rasiel P. &  Thomas V.  |
| Team B   |  Erik B. & Pa S.    |
| Team C   |  Preston D. &  Eric S.    |
| Team D   |  Sree G. &  Ben M.  |
| Team E   |  Ethan G.  &  Hondo M.   |
| Team F   |  Noah I. &  Karunakar K.   |


## ACTIVITY 1: 

1. Create a new file in your repo called "Assignment5CollaborationFile.md"
2. Each member of the team will clone the repo of the other team members.   
3. Make a local branch that is named with your name. 
4. Make changes to the file, commit, and publish the branch. 
5. Submit a pull request.   
6. The owner of the repo accepts or rejects the pull request to merge the branches based on the changes that were made .  
7. In your markdown file discussion any problems you had with "merge conflicts." 

Example

[Assignment File](./Assignment5CollaborationFile.md)

# ADVANCED EXERCISES
### For those who did this project in a previous class

### Visit the following site and watch the film

[Deep Fakes](https://moondisaster.org/)

### Discuss 
- How easy is it for you to spot a "deep fake."  Talk about your experience with the "Moon Disaster."  

#### Answer one of the following questions 

1. What makes a deepfake "convincing"? What parallels exist between generating believable deepfakes and generating code that "seems" to work but hasn’t been properly tested?

2. How do deepfakes illustrate the limits of verification? Deepfakes often pass casual human inspection — how is this like a test suite with poor coverage? What’s the risk of relying on surface-level evaluation?

3. What happens when you deploy unverified or poorly validated models? Tie this to real-world harms: misinformation, reputational damage, manipulation. Then relate it back to software engineering — what kinds of harm can occur when you ship code without robust V&V?

4. How can we "test" a deepfake?  What would it take to verify a deepfake's accuracy? Can the same process (e.g., forensic detection, metadata analysis) be paralleled in software with logging, monitoring, and code audits?

5. Who is responsible when the output is deceptive? Explore the idea of accountability in generative systems. If a deepfake spreads misinformation, who is to blame — the model, the developer, or the user? In SE, who is responsible for bugs that escape testing?

# WHAT TO TURN IN

- Your assignment will be completed in a markdown file. 
- Name the markdown file:

```
Assignment5<Lastname>
```
- Follow the directions above to ensure that your markdown file contains everything required for the assignment.
- Ensure that your markdown file for the assignment includes appropriate screen shots. 
- In the Slack channel #github-project, post the link to your GitHub repo that you created above when you are done.

### NOTE: 
- Ensure in the root directory of your repository, you have a markdown file called "README.md."  In that file, include a link to the assignment this week. 
- Example: 

```
[Assignment #X](./Assignment#<Lastname>.md)
```
### For advanced users (those who did the project before)
- Follow the directions for "ADVANCED EXERCISES" and include your work in the markdown assignment for the week.  
- Ensure that the "ADVANCED EXERCISES" section is clearly labeled with appropriate "header markdown." 